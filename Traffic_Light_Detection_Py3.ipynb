{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work in pairs and using the starter code -- train a neural network whose input is a cropped (81x81) color image and whose output is the probability that the center pixel of that image is part of a traffic light."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topics to Discuss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "    Any combination of convolutional, fully-connected and pooling layers is possible as long as the output is the right size. Decreasing H and W can be done with pooling or changing the strides of the convolutions.\n",
    "## Learning Rate\n",
    "    Decreasing the learning rate over time can help\n",
    "## Loss\n",
    "    What is the appropriate loss for binary classification? (sigmoid cross entropy)\n",
    "## Overfitting\n",
    "    How can we tell if our net is overfitting? If the train set loss and test set loss diverge too much\n",
    "    What can we do about it? Regularization, Data Augmentation. There are also more advanced options like batchnorm and dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "######## Imports ########\n",
    "#########################\n",
    "\n",
    "import numpy as np\n",
    "import os,sys\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#### Neural Net Class ###\n",
    "#########################\n",
    "class TLNet:\n",
    "\n",
    "    def __init__(self, out_dir, data_dir=None, crop_size=81):\n",
    "        \n",
    "        #########################\n",
    "        #### Initialize Net #####\n",
    "        #########################\n",
    "        \n",
    "        self.out_dir = out_dir\n",
    "        if not os.path.exists(out_dir):\n",
    "            os.makedirs(out_dir)\n",
    "        self.data_dir = data_dir\n",
    "        self.crop_size = crop_size\n",
    "        # Tensorflow placeholders serve as input pipes that we can fill later with data from any dataset we\n",
    "        # wish (as long as its examples are the expected shape)\n",
    "        self.input_data = tf.placeholder(tf.uint8, shape=[None, crop_size, crop_size, 3], name=\"input_imgs\")\n",
    "        self.labels = tf.placeholder(tf.uint8, [None, 1], name=\"labels\")\n",
    "\n",
    "        self.model_out = self.model(self.input_data)\n",
    "        \n",
    "        # We use a sigmoid on the model output so that it's predictions will be between 0 and 1\n",
    "        # representing the likelihood in percentage terms that the input image IS a positive example\n",
    "        self.prediction = tf.nn.sigmoid(self.model_out, name=\"prediction\")\n",
    "        \n",
    "        self.loss = self.calc_loss(self.model_out, tf.cast(self.labels, tf.float32))\n",
    "        \n",
    "        self.opt = None\n",
    "        \n",
    "        # Where to save the checkpoint\n",
    "        self.model_path = os.path.join(self.out_dir, \"TLNet.ckpt\")\n",
    "\n",
    "\n",
    "    def model(self, images):\n",
    "        \n",
    "        #########################\n",
    "        ##### Architecture ######\n",
    "        #########################\n",
    "        \n",
    "        # Cast uint8 images to float32 and normalize so their values are between 0 and 1\n",
    "        # Normalization is very important in training neural nets\n",
    "        images = tf.cast(images, tf.float32)\n",
    "        images *= (1. / 256)\n",
    "        \n",
    "        # Layers of the net\n",
    "        conv1 = self.conv_layer(images, 12, 'conv1', kernel=5, stride=1)\n",
    "        conv2 = self.conv_layer(conv1, 24, 'conv2', kernel=5, stride=2)\n",
    "        conv3 = self.conv_layer(conv2, 24, 'conv3', kernel=3, stride=1)\n",
    "        conv4 = self.conv_layer(conv3, 48, 'conv4', kernel=3, stride=2)\n",
    "        conv5 = self.conv_layer(conv4, 48, 'conv5', kernel=3, stride=1)\n",
    "        conv6 = self.conv_layer(conv5, 96, 'conv6', kernel=3, stride=2)\n",
    "        conv7 = self.conv_layer(conv6, 96, 'conv7', kernel=3, stride=1)\n",
    "        conv8 = self.conv_layer(conv7, 192, 'conv8', kernel=3, stride=2)\n",
    "        conv9 = self.conv_layer(conv8, 64, 'conv9', kernel=3, stride=1)\n",
    "        conv10 = self.conv_layer(conv9, 24, 'conv10', kernel=3, stride=1)\n",
    "                \n",
    "        fc11 = self.fc_layer(conv10, output_neurons=48, name='fc11', doRelu=True)\n",
    "        fc12 = self.fc_layer(fc11, output_neurons=1, name='fc12', doRelu=False)\n",
    "    \n",
    "        output = tf.identity(fc12, name='output')\n",
    "\n",
    "        return output\n",
    "\n",
    "    def calc_loss(self, model_out, label):\n",
    "        \n",
    "        #########################\n",
    "        ######### Loss ##########\n",
    "        #########################\n",
    "        \n",
    "        # Sigmoid cross entropy is the go-to loss for yes/no classification tasks\n",
    "        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=model_out, labels=label))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def save(self, sess, model_path):\n",
    "        \n",
    "        # Save the current model\n",
    "        saver = tf.train.Saver()\n",
    "        save_path = saver.save(sess, model_path)\n",
    "        return save_path\n",
    "\n",
    "    def restore(self, sess, model_path):\n",
    "        \n",
    "        # Restore previously trained model\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, model_path)\n",
    "\n",
    "    def train(self, iters, learning_rate, batch_size, restore=False, ckpt_path=None):\n",
    "        \n",
    "        #########################\n",
    "        ####### Train Net #######\n",
    "        #########################\n",
    "        \n",
    "        # Prep data\n",
    "                \n",
    "        dataset_train = self.prep_data(os.path.join(self.data_dir, 'train', 'data.bin'), \n",
    "                                 os.path.join(self.data_dir, 'train', 'labels.bin'), \n",
    "                                 batch_size=batch_size, crop_size=self.crop_size)\n",
    "        dataset_val = self.prep_data(os.path.join(self.data_dir, 'val', 'data.bin'), \n",
    "                                os.path.join(self.data_dir, 'val', 'labels.bin'), \n",
    "                                batch_size=batch_size, crop_size=self.crop_size)\n",
    "\n",
    "        train_iterator = tf.data.Iterator.from_structure(dataset_train.output_types, dataset_train.output_shapes)\n",
    "        batch_of_train_images = train_iterator.get_next()\n",
    "        train_iterator = train_iterator.make_initializer(dataset_train)\n",
    "\n",
    "        val_iterator = tf.data.Iterator.from_structure(dataset_val.output_types, dataset_val.output_shapes)\n",
    "        batch_of_val_images = val_iterator.get_next()\n",
    "        val_iterator = val_iterator.make_initializer(dataset_val)\n",
    "        \n",
    "        if not self.opt:\n",
    "            \n",
    "            # Define optimizer\n",
    "            self.opt = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            # Initialize variables and data iterators\n",
    "            sess.run(train_iterator)\n",
    "            sess.run(val_iterator)\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            if restore:\n",
    "                # Restore trained weights and biases from checkpoint\n",
    "                self.restore(sess, ckpt_path)\n",
    "\n",
    "                print (\"Resuming from previously saved checkpoint ...\")\n",
    "                \n",
    "            # Define losses and accuracy\n",
    "            train_loss = 0.\n",
    "            val_loss = 0.\n",
    "            val_accuracy = 0.\n",
    "\n",
    "            # Train\n",
    "            for i in range(iters):\n",
    "\n",
    "                try:\n",
    "                    # Get a batch of images and labels from the training data generator\n",
    "                    train_batch = sess.run(batch_of_train_images)\n",
    "                    train_images = train_batch[0]\n",
    "                    train_labels = train_batch[1]\n",
    "                    \n",
    "                    # Run the optimizer (this is where the real training is occurring)\n",
    "                    _, out_loss = sess.run([self.opt, self.loss], feed_dict=\n",
    "                                           {self.input_data: train_images, self.labels: train_labels})\n",
    "                    \n",
    "                    # Update the loss average over all of training\n",
    "                    train_loss += np.mean(out_loss)\n",
    "\n",
    "                    if (i+1) % 10 == 0:\n",
    "                        # Print loss statement\n",
    "                        print (\"Iter: \" + str(i+1) + \", Current train loss: %f\" % (train_loss / (i+1)))\n",
    "\n",
    "                    if (i+1) % 100 == 0:\n",
    "                        # Save checkpoint\n",
    "                        print (\"Saving checkpoint\")\n",
    "                        save_path = self.save(sess, self.model_path)\n",
    "\n",
    "                    if (i+1) % 100 == 0:\n",
    "                        # Evaluate the net on the validation set\n",
    "                        print (\"Performing Evaluation\")\n",
    "                        \n",
    "                        val_batch = sess.run(batch_of_val_images)\n",
    "                        val_images = val_batch[0]\n",
    "                        val_labels = val_batch[1]\n",
    "\n",
    "                        out_prediction, out_val_loss = sess.run([self.prediction, self.loss],\n",
    "                                               feed_dict={self.input_data: val_images, self.labels: val_labels})\n",
    "                        \n",
    "                        val_loss += np.mean(out_val_loss)\n",
    "                        print (\"Current loss on val set: %f\" % (val_loss / ((i+1) / 100.)))\n",
    "                        \n",
    "                        val_accuracy += np.mean(np.round(out_prediction) == val_labels)\n",
    "                        print (\"Current accuracy on val set (percent of examples labeled correctly): \" + str(float(val_accuracy / ((i+1) / 100))))\n",
    "\n",
    "\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    pass\n",
    "\n",
    "            print (\"Model saved at \" + save_path)\n",
    "\n",
    "    def evaluate(self, ckpt_path, batch_size, crop_size=81):\n",
    "        \n",
    "        #########################\n",
    "        ## Evaluate Trained Net #\n",
    "        #########################\n",
    "                \n",
    "        dataset_val = self.prep_data(os.path.join(self.data_dir, 'val', 'data.bin'), os.path.join(self.data_dir, 'val', 'labels.bin'), batch_size=batch_size, crop_size=self.crop_size)\n",
    "\n",
    "        val_iterator = tf.data.Iterator.from_structure(dataset_val.output_types, dataset_val.output_shapes)\n",
    "\n",
    "        batch_of_images = val_iterator.get_next()\n",
    "\n",
    "        input_images_test = batch_of_images[0]\n",
    "        input_labels_test = batch_of_images[1]\n",
    "\n",
    "        val_iterator = val_iterator.make_initializer(dataset_val)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            # Initialize\n",
    "            sess.run(val_iterator)\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            self.restore(sess, ckpt_path)\n",
    "\n",
    "            batch_out = sess.run(batch_of_images)\n",
    "            val_images = batch_out[0]\n",
    "            val_labels = batch_out[1]\n",
    "\n",
    "            print (\"resuming from previously saved checkpoint\")\n",
    "\n",
    "            predict_result, out_loss = sess.run([self.prediction, self.loss], feed_dict={self.input_data: val_images, self.labels: val_labels})\n",
    "\n",
    "            print (\"Loss on prediction was:\")\n",
    "            print (np.mean(out_loss))\n",
    "            print (\"Prediction was:\")\n",
    "            print (np.squeeze(predict_result))\n",
    "            print (\"Label was:\")\n",
    "            print (np.squeeze(val_labels))\n",
    "            print (\"Accuracy: %f\" % np.mean(np.round(predict_result) == val_labels))\n",
    "    \n",
    "    def predict(self, ckpt_path, img, crop_size=81):\n",
    "        \n",
    "        # FUNCTION\n",
    "        # Given an image and a checkpoint path, restore a trained model and run it on a single image\n",
    "\n",
    "        # INPUT\n",
    "        # **ckpt_path: filepath to model checkpoint\n",
    "        # **img: numpy array of shape (crop_size, crop_size, 3) and dtype uint8\n",
    "\n",
    "        # OUTPUT\n",
    "        # **prediction between 0 and 1 of how likely it is to be a traffic light\n",
    "\n",
    "        # Normalize the image, convert it to float32 and reshape it to be a single batch\n",
    "        \n",
    "        img = img.astype(np.float32) / 256.\n",
    "        img = img.reshape(1,crop_size,crop_size,3)\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            # Initialize\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            self.restore(sess, ckpt_path)\n",
    "\n",
    "            print (\"resuming from previously saved checkpoint\")\n",
    "\n",
    "            # Run inference (note that the session does not need to be fed a label because\n",
    "            # we are not calculating the loss or running the optimizer)\n",
    "            predict_result = sess.run([self.prediction], feed_dict={self.input_data: img})\n",
    "\n",
    "            return float(np.squeeze(predict_result))\n",
    "\n",
    "    \n",
    "    #########################\n",
    "    ######## Layers #########\n",
    "    #########################\n",
    "    \n",
    "    def fc_layer(self, input_tensor, output_neurons, name, doRelu=True):\n",
    "        with tf.variable_scope(name):\n",
    "                          \n",
    "            shape = input_tensor.get_shape().as_list()\n",
    "            dim = 1\n",
    "            for d in shape[1:]:\n",
    "                dim *= d\n",
    "            x = tf.reshape(input_tensor, [-1, dim])\n",
    "                          \n",
    "            activation = None\n",
    "            if doRelu:\n",
    "                activation = tf.nn.relu\n",
    "            fc = tf.layers.dense(x, output_neurons, activation=activation)\n",
    "\n",
    "            return fc\n",
    "\n",
    "\n",
    "    def conv_layer(self, input_tensor, output_channels, name, kernel=3, stride=1, doRelu=True):\n",
    "        with tf.variable_scope(name):\n",
    "            strides = (stride,stride)\n",
    "            conv = tf.layers.conv2d(input_tensor, filters=output_channels, kernel_size=kernel, strides=strides, padding='SAME', data_format='channels_last', kernel_initializer=tf.keras.initializers.glorot_normal())\n",
    "\n",
    "            if doRelu:\n",
    "                conv = tf.nn.relu(conv)\n",
    "\n",
    "            return conv\n",
    "\n",
    "    def avg_pool(self, input_tensor, name, stride=2):\n",
    "        return tf.nn.avg_pool(input_tensor, ksize=[1, 2, 2, 1], strides=[1, stride, stride, 1], padding='SAME', name=name)\n",
    "\n",
    "    def max_pool(self, input_tensor, name, stride=2):\n",
    "        return tf.nn.max_pool(input_tensor, ksize=[1, 2, 2, 1], strides=[1, stride, stride, 1], padding='SAME', name=name)\n",
    "\n",
    "    #########################\n",
    "    ##### Import Data #######\n",
    "    #########################    \n",
    "\n",
    "    def prep_data(self, g_data, g_label, batch_size, crop_size=81):\n",
    "\n",
    "        # FUNCTION\n",
    "        # Given binary files, imports data as tensorflow dataset objects\n",
    "\n",
    "        # INPUT\n",
    "        # **g_data: filepath to binary data file\n",
    "        # **g_label: filepath to binary label file\n",
    "        # **batch_size: the number of examples the dataset will supply at each iteration\n",
    "        # **crop_size: size of the input image (assumed to be square)\n",
    "\n",
    "        # OUTPUT\n",
    "        # **tensorflow dataset object\n",
    "\n",
    "        filename_dataset = tf.data.Dataset.list_files(g_data)\n",
    "\n",
    "        image_dataset = filename_dataset.map(lambda x: tf.decode_raw(tf.read_file(x), tf.uint8))\n",
    "        image_dataset = image_dataset.map(lambda x: tf.reshape(x, [-1, crop_size, crop_size, 3]))\n",
    "        image_dataset = image_dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices(x))\n",
    "        image_dataset = image_dataset.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "        filename_dataset = tf.data.Dataset.list_files(g_label)\n",
    "\n",
    "        label_dataset = filename_dataset.map(lambda x: tf.decode_raw(tf.read_file(x), tf.uint8))\n",
    "        label_dataset = label_dataset.map(lambda x: tf.reshape(x, [-1, 1]))\n",
    "        label_dataset = label_dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices(x))\n",
    "        label_dataset = label_dataset.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "        full_dataset = tf.data.Dataset.zip((image_dataset, label_dataset))\n",
    "        full_dataset = full_dataset.prefetch(buffer_size=batch_size*5)\n",
    "        full_dataset = full_dataset.shuffle(buffer_size=batch_size*10)\n",
    "        full_dataset = full_dataset.repeat()\n",
    "\n",
    "        return full_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa231fcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa231fcf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa231fcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa231fcf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa2873a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa2873a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa2873a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa2873a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa24112b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa24112b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa24112b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa24112b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa2411518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa2411518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa2411518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa2411518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa231f630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa231f630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa231f630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa231f630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa25b5ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa25b5ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa25b5ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa25b5ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa205ec88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa205ec88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa205ec88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa205ec88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fff6c716160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fff6c716160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fff6c716160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fff6c716160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa25b5128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa25b5128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa25b5128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fffa25b5128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fff6c716160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fff6c716160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fff6c716160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fff6c716160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fffa234aeb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fffa234aeb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fffa234aeb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fffa234aeb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fff6c406e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fff6c406e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fff6c406e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fff6c406e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/mobileye/algo_RP_8/jeff/wework/bigger_dataset/'\n",
    "# out_dir = '/mobileye/algo_RP_8/jeff/wework/model'\n",
    "out_dir = '/tmp/wework'\n",
    "ckpt_path = '/mobileye/algo_RP_8/jeff/wework/model/TLNet.ckpt'\n",
    "model = TLNet(data_dir=data_dir, out_dir=out_dir, crop_size=81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 10, Current train loss: 0.692899\n",
      "Iter: 20, Current train loss: 0.692655\n",
      "Iter: 30, Current train loss: 0.691639\n",
      "Iter: 40, Current train loss: 0.689556\n",
      "Iter: 50, Current train loss: 0.685356\n",
      "Iter: 60, Current train loss: 0.688273\n",
      "Iter: 70, Current train loss: 0.688261\n",
      "Iter: 80, Current train loss: 0.686464\n",
      "Iter: 90, Current train loss: 0.680051\n",
      "Iter: 100, Current train loss: 0.670441\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.700589\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.7083333333333334\n",
      "Iter: 110, Current train loss: 0.653308\n",
      "Iter: 120, Current train loss: 0.639756\n",
      "Iter: 130, Current train loss: 0.638481\n",
      "Iter: 140, Current train loss: 0.632585\n",
      "Iter: 150, Current train loss: 0.619496\n",
      "Iter: 160, Current train loss: 0.609593\n",
      "Iter: 170, Current train loss: 0.598462\n",
      "Iter: 180, Current train loss: 0.586467\n",
      "Iter: 190, Current train loss: 0.577162\n",
      "Iter: 200, Current train loss: 0.573594\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.594704\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.7083333333333334\n",
      "Iter: 210, Current train loss: 0.567193\n",
      "Iter: 220, Current train loss: 0.562233\n",
      "Iter: 230, Current train loss: 0.553464\n",
      "Iter: 240, Current train loss: 0.548982\n",
      "Iter: 250, Current train loss: 0.569033\n",
      "Iter: 260, Current train loss: 0.572399\n",
      "Iter: 270, Current train loss: 0.575926\n",
      "Iter: 280, Current train loss: 0.578826\n",
      "Iter: 290, Current train loss: 0.580542\n",
      "Iter: 300, Current train loss: 0.580778\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.608117\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.6944444444444445\n",
      "Iter: 310, Current train loss: 0.580249\n",
      "Iter: 320, Current train loss: 0.577981\n",
      "Iter: 330, Current train loss: 0.572819\n",
      "Iter: 340, Current train loss: 0.569062\n",
      "Iter: 350, Current train loss: 0.564703\n",
      "Iter: 360, Current train loss: 0.559312\n",
      "Iter: 370, Current train loss: 0.554515\n",
      "Iter: 380, Current train loss: 0.550510\n",
      "Iter: 390, Current train loss: 0.545594\n",
      "Iter: 400, Current train loss: 0.544962\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.640881\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.6875\n",
      "Iter: 410, Current train loss: 0.542483\n",
      "Iter: 420, Current train loss: 0.539477\n",
      "Iter: 430, Current train loss: 0.536312\n",
      "Iter: 440, Current train loss: 0.535202\n",
      "Iter: 450, Current train loss: 0.532307\n",
      "Iter: 460, Current train loss: 0.529024\n",
      "Iter: 470, Current train loss: 0.528748\n",
      "Iter: 480, Current train loss: 0.526567\n",
      "Iter: 490, Current train loss: 0.524386\n",
      "Iter: 500, Current train loss: 0.521664\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.578544\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.7333333333333333\n",
      "Iter: 510, Current train loss: 0.520126\n",
      "Iter: 520, Current train loss: 0.519036\n",
      "Iter: 530, Current train loss: 0.516605\n",
      "Iter: 540, Current train loss: 0.515628\n",
      "Iter: 550, Current train loss: 0.513133\n",
      "Iter: 560, Current train loss: 0.511216\n",
      "Iter: 570, Current train loss: 0.509309\n",
      "Iter: 580, Current train loss: 0.507555\n",
      "Iter: 590, Current train loss: 0.506688\n",
      "Iter: 600, Current train loss: 0.505132\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.547108\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.75\n",
      "Iter: 610, Current train loss: 0.503750\n",
      "Iter: 620, Current train loss: 0.502517\n",
      "Iter: 630, Current train loss: 0.500284\n",
      "Iter: 640, Current train loss: 0.498731\n",
      "Iter: 650, Current train loss: 0.497406\n",
      "Iter: 660, Current train loss: 0.494886\n",
      "Iter: 670, Current train loss: 0.495582\n",
      "Iter: 680, Current train loss: 0.494697\n",
      "Iter: 690, Current train loss: 0.493350\n",
      "Iter: 700, Current train loss: 0.491173\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.512339\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.7738095238095238\n",
      "Iter: 710, Current train loss: 0.491380\n",
      "Iter: 720, Current train loss: 0.490138\n",
      "Iter: 730, Current train loss: 0.488593\n",
      "Iter: 740, Current train loss: 0.488577\n",
      "Iter: 750, Current train loss: 0.489141\n",
      "Iter: 760, Current train loss: 0.488988\n",
      "Iter: 770, Current train loss: 0.487676\n",
      "Iter: 780, Current train loss: 0.487129\n",
      "Iter: 790, Current train loss: 0.486732\n",
      "Iter: 800, Current train loss: 0.485045\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.524795\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.7708333333333334\n",
      "Iter: 810, Current train loss: 0.485163\n",
      "Iter: 820, Current train loss: 0.484339\n",
      "Iter: 830, Current train loss: 0.483866\n",
      "Iter: 840, Current train loss: 0.482964\n",
      "Iter: 850, Current train loss: 0.482244\n",
      "Iter: 860, Current train loss: 0.480462\n",
      "Iter: 870, Current train loss: 0.480086\n",
      "Iter: 880, Current train loss: 0.479579\n",
      "Iter: 890, Current train loss: 0.478174\n",
      "Iter: 900, Current train loss: 0.476323\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.504717\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.7731481481481483\n",
      "Iter: 910, Current train loss: 0.474791\n",
      "Iter: 920, Current train loss: 0.473988\n",
      "Iter: 930, Current train loss: 0.472319\n",
      "Iter: 940, Current train loss: 0.471943\n",
      "Iter: 950, Current train loss: 0.471187\n",
      "Iter: 960, Current train loss: 0.470237\n",
      "Iter: 970, Current train loss: 0.469157\n",
      "Iter: 980, Current train loss: 0.467239\n",
      "Iter: 990, Current train loss: 0.466561\n",
      "Iter: 1000, Current train loss: 0.466299\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.515106\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.7666666666666667\n",
      "Model saved at /tmp/wework/TLNet.ckpt\n"
     ]
    }
   ],
   "source": [
    "model.train(1000, .0005, 24, restore=False, ckpt_path=ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /mobileye/algo_RP_8/jeff/wework/model/TLNet.ckpt\n",
      "resuming from previously saved checkpoint\n",
      "Loss on prediction was:\n",
      "0.4530408\n",
      "Prediction was:\n",
      "[0.12937275 0.91330326 0.05714411 0.6580207  0.0279949  0.49469748\n",
      " 0.42430803 0.7584258  0.02791506 0.52023035 0.02983841 0.2955702\n",
      " 0.05344415 0.18575814 0.01340783 0.42625543 0.7767383  0.56989825\n",
      " 0.02343401 0.51993155 0.03575003 0.414686   0.02354813 0.44519714\n",
      " 0.03339282]\n",
      "Label was:\n",
      "[0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0]\n",
      "Accuracy: 0.720000\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(ckpt_path=ckpt_path, batch_size=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /mobileye/algo_RP_8/jeff/wework/model/TLNet.ckpt\n",
      "resuming from previously saved checkpoint\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0010309017961844802"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_image = np.zeros((81,81,3), dtype=np.uint8)\n",
    "model.predict(ckpt_path, fake_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
